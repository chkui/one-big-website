webpackJsonp([2],{356:function(s,n,a){"use strict";Object.defineProperty(n,"__esModule",{value:!0});n.content='<p><a href="https://www.chkui.com/article/spring/spring_core_bean_post_processors" title="Spring核心——IOC处理器扩展">上一篇文章</a>介绍了非侵入式的框架的概念以及IOC的功能扩展点之一——BeanPostProcessor，我们接下来的内容继续说明IoC更多的扩展方法。\n</p>\n\n<h2 id="h2-1">BeanFactoryPostProcessor</h2>\n<p>BeanFactoryPostProcessor是针对整个容器的后置处理器。他的使用也非常简单，只要向容器中添加一个继承BeanFactoryPostProcessor的Bean即可。</p>\n\n<h3 id="h3-1">如何使用</h3>\n<p>继承了BeanFactoryPostProcessor接口的类PostProcessors：</p>\n<pre><code class="java"><span class="code-keyword">package</span> chkui.springcore.example.xml.beanfactorypostprocessor;\n\n<span class="code-keyword">public</span> <span class="hljs-class"><span class="code-keyword">class</span> <span\n            class="code-title">PostProcessors</span> <span class="code-keyword">implements</span> <span\n            class="code-title">BeanFactoryPostProcessor</span></span>{\n<span class="code-meta">@Override</span>\n\t<span class="hljs-function"><span class="code-keyword">public</span> <span class="code-keyword">void</span> <span\n            class="code-title">postProcessBeanFactory</span><span class="hljs-params">(ConfigurableListableBeanFactory beanFactory)</span> <span\n            class="code-keyword">throws</span> BeansException </span>{\n         <span class="code-comment">//DO</span>\n    }\n}</code></pre>\n<p>然后再向容器中添加这个Bean就增加了一个BeanFactoryPostProcessor。</p>\n<pre><code class="xml"><span class="php"><span class="code-meta">&lt;?</span>xml version=<span\n        class="code-string">"1.0"</span> encoding=<span class="code-string">"UTF-8"</span><span\n        class="code-meta">?&gt;</span></span>\n<span class="code-comment">&lt;!-- xml.beanfactorypostprocessor --&gt;</span>\n<span class="code-tag">&lt;<span class="code-name">beans</span>&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.PostProcessors"</span> /&gt;</span>\n<span class="code-tag">&lt;/<span class="code-name">beans</span>&gt;</span></code></pre>\n<p>BeanFactoryPostProcessor主要用于处理容器相关的内容，他被触发时机是在IoC容器加载完各种配置后，还没执行Bean的初始化之前。这个时候除了PostProcessors这个Bean，其他任何Bean都没有被创建。&nbsp;所以在BeanFactoryPostProcessor处理Bean是不合适的，Bean应该要到BeanPostProcessor中去处理，2者的区别就是前者面向容器，后者面向Bean。接下来将通过一个详细例子来说明BeanFactoryPostProcessor和BeanPostProcessor的区别以及使用方式。期间还会介绍BeanDefinitio相关的内容。</p>\n\n<h3 id="h3-2">BeanFactoryPostProcessor与BeanPostProcessor使用</h3>\n<p><span style="color:#e74c3c">（文中仅仅是示例代码，无法运行，源码在</span><a href="https://gitee.com/chkui-com/spring-core-sample"\n                                                            rel="nofollow"><span style="color:#e74c3c">https://gitee.com/chkui-com/spring-core-sample</span></a><span\n        style="color:#e74c3c">，如需下载请自行clone）</span></p>\n\n<h4 id="h4-1"><span style="color:null">建造者模式</span></h4>\n<p>下面将会通过一个例子介绍2者的使用方式和使用场景。例子使用建造者模式模拟组装一台个人电脑，分为一下3步：</p>\n<ol>\n    <li>&nbsp;容器启动之后，会将电脑的所有“配件”（Cpu、Graphics、Ram）都添加到容器中。</li>\n    <li>&nbsp;在PostProcessorS实现BeanFactoryPostProcessor接口，它的功能是向容器添加一个Pc对象。</li>\n    <li>&nbsp;在PostProcessor实现BeanPostProcessor接口。他的工作是组装电脑——每一个Bean都会检查域上的@Autowired注解，并注入对应的部件，部件也会标记自己所属的电脑。</li>\n</ol>\n<p>下面是XML配置文件，它负责将Cpu、显卡、内存等电脑常用品牌的部件放置到容器中等待组装。此外它还添加了PostProcessorS和PostProcessor两个后置处理器用于装载电脑。</p>\n<pre><code class="xml"><span class="code-tag">&lt;<span class="code-name">beans</span>&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.bean.Cpu"</span>&gt;</span>\n     \t<span class="code-tag">&lt;<span class="code-name">property</span> <span class="hljs-attr">name</span>=<span\n                class="code-string">"brand"</span> <span class="hljs-attr">value</span>=<span\n                class="code-string">"Amd"</span>/&gt;</span>\n    <span class="code-tag">&lt;/<span class="code-name">bean</span>&gt;</span>\n    \n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.bean.Graphics"</span>&gt;</span>\n     \t<span class="code-tag">&lt;<span class="code-name">property</span> <span class="hljs-attr">name</span>=<span\n                class="code-string">"brand"</span> <span class="hljs-attr">value</span>=<span class="code-string">"Nvdia"</span>/&gt;</span>\n    <span class="code-tag">&lt;/<span class="code-name">bean</span>&gt;</span>\n    \n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.bean.Ram"</span>&gt;</span>\n     \t<span class="code-tag">&lt;<span class="code-name">property</span> <span class="hljs-attr">name</span>=<span\n                class="code-string">"brand"</span> <span class="hljs-attr">value</span>=<span class="code-string">"Kingston"</span>/&gt;</span>\n    <span class="code-tag">&lt;/<span class="code-name">bean</span>&gt;</span>\n    \n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.PostProcessor"</span> /&gt;</span>\n    \n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"chkui.springcore.example.xml.beanfactorypostprocessor.PostProcessors"</span> /&gt;</span>\n<span class="code-tag">&lt;/<span class="code-name">beans</span>&gt;</span></code></pre>\n<p>下面是一个Cpu对象的结构，他标记了品牌和所属电脑。Graphics和Ram的结构和它一模一样。</p>\n<pre><code class="java"><span class="code-keyword">package</span> chkui.springcore.example.xml.beanfactorypostprocessor.bean;\n\n<span class="code-keyword">public</span> <span class="hljs-class"><span class="code-keyword">class</span> <span\n            class="code-title">Cpu</span> </span>{\n\t<span class="code-keyword">private</span> String brand;\n\t\n\t<span class="code-meta">@Autowired</span>\n\t<span class="code-keyword">private</span> Pc belong;\n}</code></pre>\n<p>注意这里的@Autowired注解，我们的配置文件并没有开启Spring的自动装配功能，我们将在PostProcessor实现自动装配。</p>\n<p>PostProcessorS的作用是向容器动态添加一个之前未定义的Bean——Pc。</p>\n<pre><code class="java"><span class="code-keyword">package</span> chkui.springcore.example.xml.beanfactorypostprocessor;\n\n<span class="code-keyword">public</span> <span class="hljs-class"><span class="code-keyword">class</span> <span\n            class="code-title">PostProcessors</span> <span class="code-keyword">implements</span> <span\n            class="code-title">BeanFactoryPostProcessor</span></span>{\n\t<span class="code-meta">@Override</span>\n\t<span class="hljs-function"><span class="code-keyword">public</span> <span class="code-keyword">void</span> <span\n            class="code-title">postProcessBeanFactory</span><span class="hljs-params">(ConfigurableListableBeanFactory beanFactory)</span> <span\n            class="code-keyword">throws</span> BeansException </span>{\n\t\t<span class="code-comment">//获取容器的注册接口</span>\n\t\tBeanDefinitionRegistry registry = (BeanDefinitionRegistry)beanFactory;\n\t\t<span class="code-comment">//新建一个BeanDefinition用于动态装配Bean</span>\n\t\tGenericBeanDefinition defininition = <span class="code-keyword">new</span> GenericBeanDefinition();\n\t\t<span class="code-comment">//设置要添加的类</span>\n\t\tdefininition.setBeanClass(Pc.class);\n\t\t<span class="code-comment">//注册BeanDefinition</span>\n\t\tregistry.registerBeanDefinition(<span class="code-string">"postBean"</span>, defininition);\n\t}\n}</code></pre>\n<p>如果看过 <a href="https://www.chkui.com/article/spring/spring_core_context_and_ioc" title="Spring核心——上下文与IoC">Ioc结构介绍的这篇文章</a>，你就会知道BeanFactory经过层层派生，实际上大部分接口都在一个类实现——DefaultListableBeanFactory，它除了实现ConfigurableListableBeanFactory接口，还实现了BeanDefinitionRegistry接口。BeanDefinitionRegistry提供了BeanDefinition的管理功能。\n</p>\n\n<h4 id="h4-2">BeanDefinition与适配器模式</h4>\n<p>\n    在上面的代码中出现了BeanDefinition接口，这里就顺道说一说这个有趣的小玩意。关于他如何使用Spring的官网并没有太详细的介绍（至少我没找到），网上倒是有各路大神的博客在解读他的源码，不过代码只是表象，要理解他的整套设计思路才能提升。</p>\n<p>关于BeanDefinition的使用模式，官网将其称呼为<em>configuration metadata</em>，直译过来叫“配置元数据”。&nbsp;他的作用有点类似于<a\n        href="https://www.chkui.com/article/spring/spring_core_context_and_ioc" title="Spring核心——上下文与IoC">Context分层应用的效果（见Spring核心——上下文与IoC&nbsp;关于\n    ApplicationContext的说明）</a>，目的就是将Bean的配置和初始化工作分成2个互不干扰的部分。</p>\n<p>我们知道 Spring现在支持各种各样的方式来添加Bean，比如在XML配置文件中使用&lt;bean&gt;标签、使用@Component以及他的派生类注解、可以在@Configuration类中生成、甚至还可以通过RMI实现远程配置等等。如果所有的这些配置来源直接和IoC容器产生关系生成Bean，那么耦合度、代码复杂度会越来越高，而且以后指不定什么时候又会加入什么新的配置方式。</p>\n<p>\n    为了解决这个问题Spring的大神们引入了适配器模式——IoC容器只接受BeanDefinition接口，IoC如何初始化一个Bean是仅仅是看BeanDefinition里的信息。而各种配置方式都有自己的适配器，所有的适配器都会根据他所需要处理的内容来生成一个BeanDefinition的实现类。这样，如果新增一个新的配置方式，增加一个适配器就可以搞定。</p>\n<p><img align="left" alt="Spring核心——IOC功能扩展点" height="381"\n        src="https://static.oschina.net/uploads/img/201807/11171429_ggwk.png" width="600"></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p>所以，我们也可以利用BeanDefinitionRegistry接口向容器添加一个BeanDefinition，进而在随后的执行过程中IoC容器会根据 这个BeanDefinition创建一个对应的Bean。</p>\n\n<h4 id="h4-3">BeanPostProcessor</h4>\n<p>\n    前面已经提到，BeanFactoryPostProcessor用于处理容器级别的问题，而BeanPostProcessor用来处理每一个Bean。我们前面已经用BeanFactoryPostProcessor向容器添加了一个Pc对象的Bean，接下来我们在BeanPostProcessor中处理每一个Bean的自动注入注解。</p>\n<pre><code class="java"><span class="code-keyword">package</span> chkui.springcore.example.xml.beanfactorypostprocessor;\n\n<span class="code-keyword">public</span> <span class="hljs-class"><span class="code-keyword">class</span> <span\n            class="code-title">PostProcessor</span> <span class="code-keyword">implements</span> <span\n            class="code-title">BeanPostProcessor</span>, <span class="code-title">BeanFactoryAware</span> </span>{\n\t<span class="code-keyword">private</span> ConfigurableListableBeanFactory beanFactory;\n\t<span class="hljs-function"><span class="code-keyword">public</span> Object <span class="code-title">postProcessBeforeInitialization</span><span\n            class="hljs-params">(Object bean, String beanName)</span> </span>{\n        <span class="code-keyword">return</span> autowiredImplement(bean);\n    }\n\t<span class="hljs-function"><span class="code-keyword">public</span> Object <span class="code-title">postProcessAfterInitialization</span><span\n            class="hljs-params">(Object bean, String beanName)</span> </span>{\n        <span class="code-keyword">return</span> bean;\n    }\n\t\n\t<span class="code-comment">//自定义实现autowired功能</span>\n\t<span class="hljs-function"><span class="code-keyword">private</span> Object <span class="code-title">autowiredImplement</span><span\n            class="hljs-params">(<span class="code-keyword">final</span> Object bean)</span> </span>{\n\t\t<span class="code-keyword">for</span>(Field field : bean.getClass().getDeclaredFields()) {\n\t\t\tAutowired value = field.getAnnotation(Autowired.class);\n\t\t\t<span class="code-keyword">if</span>(<span class="code-keyword">null</span> != value) {\n\t\t\t\tObject obj = beanFactory.getBean(field.getType());\n\t\t\t\tfield.setAccessible(<span class="code-keyword">true</span>);\n\t\t\t\tfield.set(bean, obj);\n\t\t\t}\n\t\t}\n\t\t<span class="code-keyword">return</span> bean;\n\t}\n\t<span class="code-meta">@Override</span>\n\t<span class="hljs-function"><span class="code-keyword">public</span> <span class="code-keyword">void</span> <span\n            class="code-title">setBeanFactory</span><span class="hljs-params">(BeanFactory beanFactory)</span> <span\n            class="code-keyword">throws</span> BeansException </span>{\n\t\t<span class="code-keyword">this</span>.beanFactory = (ConfigurableListableBeanFactory)beanFactory;\n\t}\n}</code></pre>\n<p>这里的PostProcessor实现BeanFactoryAware接口来获取&nbsp;BeanFactory。自动注入的处理逻辑都在autowiredImplement方法中，它会扫描Bean的每一个域检查是否有@Autowired注解，如果有则根据这个域的Class类型到BeanFactory去获取对应的Bean，然后反射注入。</p>\n<p>最后我们创建一个ApplicationContext来运行他们：</p>\n<pre><code class="java"><span class="code-keyword">public</span> <span class="hljs-class"><span class="code-keyword">class</span> <span\n        class="code-title">SampleApp</span> </span>{\n    <span class="hljs-function"><span class="code-keyword">public</span> <span class="code-keyword">static</span> <span\n            class="code-keyword">void</span> <span class="code-title">main</span><span class="hljs-params">(String[] args)</span> </span>{\n    \tApplicationContext context = <span class="code-keyword">new</span> ClassPathXmlApplicationContext(<span\n            class="code-string">"xml/beanfactorypostprocessor/config.xml"</span>);\n    \tPc pc = context.getBean(Pc.class);\n        <span class="code-comment">/**\n        Pc Info: Graphics=Nvdia, Cpu=Amd, Ram=Kingston]\n        */</span>\n        System.out.println(pc);\n    }\n}</code></pre>\n<p>本文介绍了BeanFactoryPostProcessor和BeanPostProcessor的使用方式，以及IoC容易是如何通过BeanDefinition装载各种配置的。后续还会持续介绍Spring\n    IoC容器的各种功能扩展点。</p>'},359:function(s,n,a){"use strict";Object.defineProperty(n,"__esModule",{value:!0});n.content='<h2 id="h2-1">JSR-175与元编程</h2>\n<p>要说明JSR-250先要解释清楚JSR-175，要解释清楚JSR就的先了解JCP是什么。网上资料很多，就不细说了，简单的说JCP（Java Community\n    Process）是管理Java生态（包括J2SE、J2EE等等）发展的合作组织。JSR（Java Specification\n    Request）就是组织内的成员针对Java的发展提出的一些需求，通过审核之后即会融入到新版本的Java功能中成为Java的一项特性或功能，不同的发行版本和虚拟机都会遵守这些约定。</p>\n<p>JSR-175的全文标题是<strong><span style="color:null">&nbsp;A Metadata Facility for the Java&nbsp;Programming Language （为Java语言提供元数据设施）</span></strong>。它明确提出了在Java平台引入“元编程”（Meta\n    Programming）的思想，要求提供对“元数据”（Meta Data）的支持。这就是我们现在大量使用的“@”注解（Annotation）功能的最早来源。JSR-175之后的JSR-181（Web服务支持）、JSR-250、<a\n            href="https://www.chkui.com/article/java/java_jsr330" title="JSR-330">JSR-330</a>都是基于“元数据”功能提出的一些更细节的实现。</p>\n<p>至于“元编程”、“元数据”是什么这里就不详细展开说明了，它的理论很早就提出了，据说最早是在Lisp这一类函数式编程语言上开始使用的。网上有很多相关的资料，简单的说它就是“对源码进行编码”，比如下面这样：</p>\n<pre><code class="java"><span class="hljs-class"><span class="code-keyword">class</span> <span class="code-title">MyClass</span> </span>{\n\t<span class="code-meta">@Autowired</span>\n\t<span class="code-keyword">private</span> Interface support;\n}</code></pre>\n<p>通过@Autowired这个注解来对support这个域进行编码就可以很轻松的扩展原先类的功能。</p>\n\n<h2 id="h2-2">JSR-250的Spring实现</h2>\n<p>JSR-250主要是围绕着“资源”的使用预定义了一些注解（Annotation）,这里的“资源”可以理解为一个Class类的实例、一个JavaBean、或者一个Spring中的Bean。</p>\n<p>JSR-250相关的注解全部在 <em>javax.annotation</em> 和 <em>javax.annotation.security </em>包中，分成2个部分——资源定义和权限控制。它并没有提供具体的实现方式，仅仅是提供了指导性的文档和几个注解，由具体的框架去实现。\n</p>\n<p><em>javax.annotation</em> 中包含一下几个注解：</p>\n<ul>\n    <li>@Generated：生成资源的注解，通过该项标记产生的实例是一个资源。类似于Spring中的@Bean注解，用于生成一向资源。</li>\n    <li>@PostConstruct&nbsp;创造资源之后的回调处理，Spring已经实现了这个注解，见<a\n            href="https://www.chkui.com/article/spring/spring_core_bean_lifecycle_callback"\n            title="Bean的定义与控制">Bean的定义与控制</a> 一文的介绍。\n    </li>\n    <li>@PreDestroy&nbsp;销毁资源之前的回调处理，Spring同样实现了这个注解，见<a\n            href="https://www.chkui.com/article/spring/spring_core_bean_lifecycle_callback"\n            title="Bean的定义与控制">Bean的定义与控制</a>。\n    </li>\n    <li>@Resource&nbsp;标记使用资源的位置，Spring同样实现了这个注解的功能（后文会详细介绍）。功能上有些类似于@Autowired、@Inject，但是两者有不少的差别。</li>\n    <li>@Resources&nbsp;标记使用多项资源的位置，类似于使用@Autowired向一个列表装载数据。</li>\n</ul>\n<p>仔细看JSR-250定义的这些注解就会发现，他们都是关于“资源”的构建、销毁、使用的。Spring实现了@PostConstruct、@PreDestroy和@Resource。</p>\n<p>javax.annotation.security&nbsp;包中有以下内容：</p>\n<ul>\n    <li>@DeclareRoles&nbsp;声明角色</li>\n    <li>@DenyAll&nbsp; 拒绝所有角色</li>\n    <li>@PermitAll&nbsp; 授权所有惧色</li>\n    <li>@RolesAllowed&nbsp; 角色授权</li>\n    <li>@RunAs 运行模式</li>\n</ul>\n<p>security中的内容是在资源创建之后对<strong><em>资源的使用进行管理</em></strong>。和常规的权限控制模型一样——定义角色（@DeclareRoles&nbsp;）、确定角色对资源的控制权限（@DenyAll、@PermitAll\n    、@RolesAllowed&nbsp;）。Spring并没有实现这里的任何一个注解，在这里就不深入介绍了。这一块内容在J2EE的构建中有不少的应用。</p>\n\n<h2 id="h2-3">Spring中的@Resource</h2>\n<p>\n    在没有仔细看Spring的官方文档和JSR-250之前，我一直以为@Resource这个注解和@Autowired是2个不同的功能，更早的时候还以为是管理什么Properties资源的，很多网上的内容也写得比较模糊。虽然@Resource的实现是在\n    <em>CommonAnnotationBeanPostProcessor</em>&nbsp;而@Autowired 是在\n    AutowiredAnnotationBeanPostProcessor，但是实际上两者的功能是重叠的，或者说@Resource的提供的功能是@Autowired的子集。</p>\n<p>在Spring中使用@Resource注解时，把Bean理解为一项资源就很好理解了。下面通过一些简单的例子来介绍@Resource的使用。</p>\n<p>@Resource的功能是告诉IoC容器标记的位置需要什么样的“资源”，如下：</p>\n<pre><code class="java"><span class="hljs-class"><span class="code-keyword">class</span> <span\n        class="code-title">Abc</span> </span>{}\n<span class="hljs-class"><span class="code-keyword">class</span> <span class="code-title">Xyz</span> </span>{}\n<span class="hljs-class"><span class="code-keyword">class</span> <span class="code-title">Implement</span> </span>{\n\t<span class="code-meta">@Resource</span>\n\t<span class="code-keyword">private</span> Abc abc;\n\t\n\t<span class="code-keyword">private</span> Xyz xyz;\n\n    <span class="code-meta">@Resource</span>\n    <span class="code-keyword">private</span> ApplicationContext context;\n\n\t<span class="code-meta">@Resource</span>(name=<span class="code-string">"b_instance"</span>)\n\t<span class="hljs-function"><span class="code-keyword">public</span> <span class="code-keyword">void</span> <span\n            class="code-title">setInject</span><span class="hljs-params">(Xyz xyz)</span> </span>{\n\t\t<span class="code-keyword">this</span>.xyz = xyz;\n\t}\n}</code></pre>\n<pre><code class="xml"><span class="code-tag">&lt;<span class="code-name">beans</span>&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">context:annotation-config</span>/&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">id</span>=<span\n            class="code-string">"abc"</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"x.y.Abc"</span> /&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">id</span>=<span\n            class="code-string">"xyz_instance"</span> <span class="hljs-attr">name</span>=<span class="code-string">"inject"</span> <span\n            class="hljs-attr">class</span>=<span class="code-string">"x.y.Xyz"</span> /&gt;</span>\n    <span class="code-tag">&lt;<span class="code-name">bean</span> <span class="hljs-attr">class</span>=<span\n            class="code-string">"x.y.Implement"</span> /&gt;</span>\n<span class="code-tag">&lt;/<span class="code-name">beans</span>&gt;</span></code></pre>\n<p>\n    运行后，IoC会向标记了@Resource的位置注入Bean——是不是感觉和@Autowired一模一样？但是需要注意的是虽然两者最后都是注入一个Bean，但是@Resource和@Autowired的处理过程是不一样的。@Autowired如果没有提供任何参数，那么他优先按照类型注入，如果要对细节进行控制可以配合Primary和Qualifiers功能，详见<a\n        href="https://www.chkui.com/article/spring/spring_core_auto_inject_of_annotation" title="注解自动装载">注解自动装载</a>的介绍。@Resource是按照命名来注入资源的，以上面的代码为例子：\n</p>\n<ol>\n    <li>例如在setter方法上定义了name="xyz_instance"参数，那么会去IoC容器中寻找id、name等于"xyz_instance"的Bean来注入。</li>\n    <li>例如在abc这个域（成员变量）上没有定义name参数，那么会使用域的名称（这里是"abc"）去IoC中按id、name寻找Bean来注入。</li>\n    <li>如果@Resource定义在方法上，并且没有指定name参数，那么他会使用setter的名称（例子中方法名为setInject，名称就是"inject"）来寻找并注入数据。</li>\n    <li>最后，如果名称匹配不上，容器会根据标记位置的类型来注入数据，例如例如中的ApplicationContext。</li>\n</ol>\n<p>所以@Resource的装载资源过程是：1)匹配name参数；2)没有name参数时会根据setter或域的名称来匹配Bean的名称；3)还是匹配不上就根据标记位置的类型来注入数据。</p>\n<p>与@Autowired相比主要有以下几点区别：</p>\n<ol>\n    <li>控制粒度没有@Autowired细，某些参数Spring并没有实现功能。但是使用他更符合整个Java生态的规范。</li>\n    <li>如果是使用类型依赖注入数据，应优先使用@Autowired，效率会好一些。</li>\n    <li>@Resource通过名称注入与@Autowired相比省去了@Qualifiers等内容。</li>\n    <li>@Resource只能用在域和Setter方法上。</li>\n</ol>\n<p>总的来说如果是按照类型注入依赖对象，那么最终得到的结果并没有任何差异，只是执行过程上有差别。如果按Bean的名称使用，@Resource比@Autowired便捷一些，但是功能少很多。</p>\n<p>个人建议如果开发的是一个面向终端用户的应用，比如Web应用、网站什么的，直接用@Autowired就好了。如果制作的是一个给别的开发人员使用的工具，可以考虑@Resourec，他能得到更多框架的支持。</p>\n\n<h2 id="h2-4">@PostConstruct 与@PreDestroy</h2>\n<p>@PostConstruct 与@PreDestroy也是JSR-250中定义的注解，Spring都实现了他们的功能，使用方法可以查看<a\n        href="https://www.chkui.com/article/spring/spring_core_bean_lifecycle_callback" title="Bean的定义与控制">Bean的定义与控制</a>&nbsp;相关的说明和介绍。\n</p>'},369:function(s,n,a){"use strict";Object.defineProperty(n,"__esModule",{value:!0});n.content='<p>本文将解释如何在Windows下安装TensorFlow。</p>\n\n<h2 id="h2-1">确定安装哪类TensorFlow</h2>\n<p>需要先确定哪种类型的TensorFlow：</p>\n<ul>\n    <li><strong>仅支持CUP运算版本：</strong>如果电脑的系统没有&nbsp;NVIDIA®的GPU，那么必须安装这个版本。这个版本的TensorFlow安装非常简单（安装仅需一个命令，5到10分钟），所以即使系统中有满足要求的NVIDIA®\n        GPU官方还是建议在学习阶段安装这个版本。\n    </li>\n    <li><strong>支持GPU运算的版本：</strong>TensorFlow程序在GPU下运行比在CPU下运行明显快很多。如果系统中包含&nbsp;NVIDIA®的GPU满足下一个小节所示的条件并且程序对性能要求很高，建议安装此版本。\n    </li>\n</ul>\n\n<h2 id="h2-2">运行TensorFlow所需要的GPU配置</h2>\n<p>如果在系统中安装使用GPU运行的TensorFlow，需要确保下面介绍的NVIDIA软件已经安装到系统中。</p>\n<ul>\n    <li>CUDA® Toolkit 8.0。请看 <a\n            href="http://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/#axzz4eDEVDKkM" rel="nofollow">NVIDIA安装cuda</a>\n        的文档，根据文档中的描述确保已经将CUDA相关的路径增加到&nbsp;<code>%PATH%</code>&nbsp;环境变量中。\n    </li>\n    <li>NVIDIA的驱动关联&nbsp;CUDA Toolkit 8.0。</li>\n    <li>cuDNN v5.1。请查看 <a href="https://developer.nvidia.com/cudnn" rel="nofollow">NVIDIA&nbsp;cudnn</a>\n        文档。需要注意的是cuDNN通常安装在与其他CUDA动态链接库（dll）不同的位置。确保已经将cuDNN的 动态链接库（dll）的地址添加到系统的&nbsp;&nbsp;<code>%PATH%</code>&nbsp;环境变量中。\n    </li>\n    <li>GPU显卡必须拥有3.0以上版本的CUDA计算能力，查看 <a href="https://developer.nvidia.com/cuda-gpus" rel="nofollow">NVIDIA显卡支持列表</a>\n        了解支持情况。\n    </li>\n</ul>\n<p>如果系统中已经安装了以前的相关包，请更新到所指定的版本。</p>\n\n<h2 id="h2-3">如何安装TensorFlow</h2>\n<p>在安装TensorFlow之前必须选定一个安装机制。目前提供2种机制：</p>\n<ul>\n    <li>"native"app</li>\n    <li>Anaconda</li>\n</ul>\n<p>\n    Native的安装（以下简称本地安装）方式会将TensorFlow直接安装在当前的系统中，不会在系统和TensorFlow之间搭建任何的虚拟环境，所以本地安装不会额外安装一个独立的容器。需要注意的是本地安装可能会干扰系统中其他基于python安装的程序。如果事先已经安装配置了满足需要的python环境，本地安装通常只需要一个命令就可以完成。使用本地安装，用户可以在系统中任何位置运行TensorFlow。</p>\n<p>在Anaconda模式下，需要使用conda创建一个虚拟环境。官方优先推荐使用&nbsp;<code>pip install</code>&nbsp;命令来安装TensorFlow，其次再考虑anaconda的&nbsp;<code>conda\n    install</code>&nbsp;命令。conda包是第三方社区提供的（非TensorFlow官方），TensorFlow团队从始至终都不会去测试在conda中运行的情况，在使用时需考虑这个风险。</p>\n\n<h3 id="h3-1">本地安装</h3>\n<p>首先，需要安装以下版本的python：</p>\n<ul>\n    <li><a href="https://www.python.org/downloads/release/python-352/" rel="nofollow">Python 3.5.x from python.org</a>\n    </li>\n</ul>\n<p>TensorFlow在windows操作系统中仅仅支持3.5.x版本的python。Python 3.5.x附带pip3软件包管理器，这是用于安装TensorFlow的程序。</p>\n<p>安装TensorFlow需要启动一个终端（terminal），然后在该终端中输入对应的pip3 install命令。安装仅支持CPU版本的TensorFlow，输入以下命令：</p>\n<pre class="lua"><code class="language-bash">C:\\&gt; pip3 install <span class="code-comment">--upgrade tensorflow</span></code></pre>\n<p>安装GPU版本的TensorFlow，使用以下命令：</p>\n<pre class="lua"><code class="language-bash">C:\\&gt; pip3 install <span\n        class="code-comment">--upgrade tensorflow-gpu</span></code></pre>\n<p>Anaconda模式安装</p>\n<p><span style="color:#FF0000">再次强调，Anaconda安装是有第三方社区提供的，非官方。</span></p>\n<p>在Anaconda环境中安装TensorFlow分为以下几个步骤：</p>\n<ol>\n    <li>按照&nbsp;<a href="https://www.continuum.io/downloads" rel="nofollow">Anaconda download site</a>&nbsp;的说明进行下载和安装操作。\n    </li>\n    <li>调用以下命令来创建一个名为tensorflow的conda环境：\n        <pre class="groovy"><code class="language-bash"><span class="code-string">C:</span>&gt; conda create -n tensorflow </code></pre>\n        <p></p></li>\n    <li><p>键入以下命令来启用conda环境：</p>\n        <pre class="yaml"><code class="language-bash"><span class="hljs-attr">C:</span>&gt; activate tensorflow\n (tensorflow)C:&gt;  <span class="code-comment"><span\n                    class="code-comment"># Your prompt should change </span></span></code></pre>\n        <p></p></li>\n    <li><p>键入以下命令在conda环境中安装TensorFlow。这里 安装CPU版本的命令：</p>\n        <pre class="groovy"><code class="language-bash">(tensorflow)<span class="code-string">C:</span>&gt; pip install --ignore-installed --upgrade <span\n                class="code-string">https:</span><span class="code-comment">//storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl </span>\n</code></pre>\n        <p>这是GPU版本的命令：</p>\n        <pre class="groovy"><code class="language-bash">(tensorflow)<span class="code-string">C:</span>&gt; pip install --ignore-installed --upgrade <span\n                class="code-string">https:</span><span class="code-comment">//storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl </span></code></pre>\n        <p></p></li>\n</ol>\n\n<h3 id="h3-2">验证安装&nbsp;</h3>\n<ol>\n    <li>通过以下步骤来验证TensorFlow是否安装成功：</li>\n    <li>启动一个终端（比如CMD）</li>\n    <li>如果通过Anaconda安装，先启动Anaconda环境。</li>\n    <li>在终端运行python</li>\n    <li>\n        <pre class="groovy"><code class="language-bash"><span class="code-string">C:</span>&gt; python </code></pre>\n    </li>\n    <li>在python的交互环境中输入以下脚本代码：</li>\n    <li> <pre class="python"><code class="python"><span class="code-meta"><span\n            class="code-meta">&gt;&gt;&gt; </span></span><span class="code-keyword"><span\n            class="code-keyword">import</span></span> tensorflow <span class="code-keyword"><span class="code-keyword">as</span></span> tf\n\n\n\n\nhello = tf.constant(<span class="code-string"><span class="code-string">\'Hello, TensorFlow!\'</span></span>)\nsess = tf.Session()\nprint(sess.run(hello))\n </code></pre>\n        <p>如果python输出以下内容，则表明TensorFlow已经安装成功然后就可以写TensorFlow的程序了：</p></li>\n    <li>\n        <pre class=""><code class="language-bash">Hello, TensorFlow!</code></pre>\n        <p>如果收到了一些异常信息，请继续向下看。</p></li>\n</ol>\n\n<h3 id="h3-3">常见的安装问题</h3>\n<p>TensorFlow通过Stack Overflow网站来记录错误信息以及处理方法。下面的列表包含一些跳转的到&nbsp;Stack Overflow的连接。如果在安装过程中遇到的问题没有在下面中，请到Stack\n    Overflow去搜索相关的关键字。若还是搜索不到，请直接提出新问题并标记&nbsp;<code>tensorflow</code>&nbsp;的标签。</p>\n<table>\n    <tbody>\n    <tr>\n        <th>Stack Overflow Link</th>\n        <th>Error Message</th>\n    </tr>\n    <tr>\n        <td><a href="https://stackoverflow.com/q/41007279" rel="nofollow">41007279</a></td>\n        <td>\n            [...\\stream_executor\\dso_loader.cc] Couldn\'t open CUDA library nvcuda.dll\n        </td>\n    </tr>\n    <tr>\n        <td><a href="https://stackoverflow.com/q/41007279" rel="nofollow">41007279</a></td>\n        <td>\n            [...\\stream_executor\\cuda\\cuda_dnn.cc] Unable to load cuDNN DSO\n        </td>\n    </tr>\n    <tr>\n        <td><a href="http://stackoverflow.com/q/42006320" rel="nofollow">42006320</a></td>\n        <td>\n            ImportError: Traceback (most recent call last): File "...\\tensorflow\\core\\framework\\graph_pb2.py", line 6,\n            in from google.protobuf import descriptor as _descriptor ImportError: cannot import name \'descriptor\'\n        </td>\n    </tr>\n    <tr>\n        <td><a href="https://stackoverflow.com/q/42011070" rel="nofollow">42011070</a></td>\n        <td>\n            No module named "pywrap_tensorflow"\n        </td>\n    </tr>\n    </tbody>\n</table>'},370:function(s,n,a){"use strict";Object.defineProperty(n,"__esModule",{value:!0});n.content='<h2 id="h2-1">TensorFlow入门</h2>\n<p>本文将初步向码农和程序媛们介绍如何使用TensorFlow进行编程。在阅读之前请先 <a href="https://www.chkui.com/article/tensorflow/tensorflow_windows_install" rel="nofollow">安装TensorFlow</a>，此外为了能够更好的理解本文的内容，阅读之前需要了解一点以下知识：\n</p>\n<ol>\n    <li>python基本编程。能看得懂python代码，最好能使用脚本工具或pycharm之类的IDC编写代码。</li>\n    <li>至少有一点数组的概念。</li>\n    <li>最理想的状态是具备机器学习的基础知识。不过如果在阅读之前没有了解过任何机器学习相关的知也无大碍，可以把本文作为了解机器学习的开端。后面会另开一篇用MNIST了解机器学习的基础知识。</li>\n</ol>\n<p>TensorFlow提供种类繁多的API接口，其中TensorFlow Core是最低层级的接口，为开发TensorFlow提供基础支持。官方推荐把TensorFlow\n    Core用作机器学习研究以及相关的数据建模。除了TensorFlow Core之外还有更高抽象的API接口，这些API接口比TensorFlow Core更易于使用、更易于快速实现业务需求。例如&nbsp;tf.contrib.learn\n    接口，它提供管理数据集合、进行数据评估、训练、推演等功能。在使用TensorFlow开发的过程中需要特别注意，以&nbsp;<code>contrib</code>&nbsp;开头的API接口依然还在不断完善中，很有可能在未来某个发行版本中进行调整或者直接取消。\n</p>\n<p>本文首先介绍TensorFlow Core，然后会演示如何使用&nbsp;tf.contrib.learn 实现简单的建模。了解TensorFlow\n    Core是为了让开发者理解在使用抽象接口时底层是如何工作的，以便于在训练数据时创建更合适的模型。</p>\n\n<h2 id="h2-2">TensorFlow</h2>\n<p>\n    TensorFlow的基础数据单元是张量（tensor）。一个张量认为是一组向量的集合，从数据结构的角度来理解这个集合等价于一组数值存储在1到多个队列中（张量没办法几句话说得清楚，想要了解去谷哥或者度妞搜索“张量分析”，可以简单想象成一个多维度的数组）。一个张量的阶表示了张量的维度，下面是一些张量的例子：</p>\n<blockquote> \n <pre class="lua"><code class="lua"><span class="hljs-number"><span class="hljs-number">3</span></span> # <span\n         class="hljs-number"><span class="hljs-number">0</span></span>阶张量，可以用图形[]来表示\n[<span class="hljs-number"><span class="hljs-number">1.</span></span> ,<span class="hljs-number"><span\n             class="hljs-number">2.</span></span>, <span class="hljs-number"><span class="hljs-number">3.</span></span>] # <span\n             class="hljs-number"><span class="hljs-number">1</span></span>阶张量，是一个图形为[<span class="hljs-number"><span\n             class="hljs-number">3</span></span>]的向量\n<span class="code-string"><span class="code-string">[[1., 2., 3.], [4., 5., 6.]]</span></span> # <span\n             class="hljs-number"><span class="hljs-number">2</span></span>阶张量，是一个图形为[<span class="hljs-number"><span\n             class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>]的矩阵\n<span class="code-string"><span class="code-string">[[[1., 2., 3.]]</span></span>, <span class="code-string"><span\n             class="code-string">[[7., 8., 9.]]</span></span>] # 图形为[<span class="hljs-number"><span\n             class="hljs-number">2</span></span>,<span class="hljs-number"><span\n             class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>]的三阶张量</code></pre>\n</blockquote>\n\n<h2 id="h2-3">TensorFlow Core教程</h2>\n\n<h3 id="h3-1">导入TensorFlow</h3>\n<p>下面是导入TensorFlow包的标准方式：</p>\n<pre class="haskell"><code class="language-python"><span class="code-keyword"><span\n        class="code-keyword">import</span></span> tensorflow <span class="code-keyword"><span\n        class="code-keyword">as</span></span> tf</code></pre>\n<p>通过python的方式导入之后，&nbsp;tf 提供了访问所有TensorFlow类、方法和符号的入口。</p>\n\n<h3 id="h3-2">图计算（Computational Graph）</h3>\n<p>TensorFlow Core的编程开发可以看就做2个事：</p>\n<ol>\n    <li>构建计算图。（建模）</li>\n    <li>运行计算图。（执行）</li>\n</ol>\n<blockquote>\n    <p>图（graph，也可以叫连接图）表示由多个点链接而成的图。本文中的图指的是TensorFlow建模后运算的路径，可以使用TensorBoard看到图的整个形态。</p>\n    <p>节点（node）表示图中每一个点，这些点都代表了一项计算任务。</p>\n</blockquote>\n<p><strong>所以简而言之</strong>：编程 <em>TensorFlow Core</em> 就是事先安排好一系列节点的计算任务，然后运行这些任务。</p>\n<p>\n    下面我们先构建一个简单的图，图中的节点（node）有0或多个张量作为输入，并产生一个张量作为输出。一个典型的节点是“常量”（constant）。TensorFlow的常量在构建计算模型时就已经存在，在运行计算时并不需要任何输入。下面的代码创建了2个浮点常量值常量&nbsp;<code>node1</code>&nbsp;和&nbsp;<code>node2</code>：\n</p>\n<pre class="go"><code class="language-python">node1 = tf.constant(<span class="hljs-number"><span class="hljs-number">3.0</span></span>, tf.<span\n        class="code-keyword">float32</span>)\nnode2 = tf.constant(<span class="hljs-number"><span class="hljs-number">4.0</span></span>) <span class="code-comment"># also tf.<span\n            class="code-keyword">float32</span> implicitly</span>\n<span class="code-built_in">print</span>(node1, node2)</code></pre>\n<p>运行后会打印输出：</p>\n<pre class="lisp"><code class="language-python">Tensor(<span class="code-string"><span\n        class="code-string">"Const:0"</span></span>, shape=(), dtype=float32) Tensor(<span class="code-string"><span\n        class="code-string">"Const_1:0"</span></span>, shape=(), dtype=float32)</code></pre>\n<p>观察这个打印的结果会发现，它并不是按照预想的那样输出 <em>3.0</em> 或<em> 4.0 </em>的值。这里输出的是一个节点的对象信息。因为到这里还没有执行第二项工作——运行计算模型图。只有在运行时，才会使用到节点真实的值\n    <em>3.0</em> 和<em>4.0</em>。为了进行图运算需要创建一个会话（session），一个会话封装了TensorFlow运行库的各种控制方法和状态量（context）。</p>\n<p>下面的代码会创建一个会话（session）对象实例，然后执行&nbsp;<code>run</code>&nbsp;方法来进行模型计算：</p>\n<pre class="lua"><code class="language-python">sess = tf.Session()\n<span class="code-built_in">print</span>(sess.run([node1, node2]))</code></pre>\n<p>运行后我们会发现，打印的结果是3.0和4.0：</p>\n<pre class="json"><code class="language-python">[<span class="hljs-number"><span class="hljs-number">3.0</span></span>, <span\n        class="hljs-number"><span class="hljs-number">4.0</span></span>]</code></pre>\n<p>\n    然后，对&nbsp;<code>node1</code>&nbsp;和&nbsp;<code>node2</code>&nbsp;进行和运算，这个和运算就是图中的运算模型。下面的代码是构建一个&nbsp;<code>node1</code>&nbsp;、&nbsp;<code>node2</code>&nbsp;进行和运算，&nbsp;<code>node3</code>&nbsp;代表和运算的模型，构建完毕后使用\n    <code>sess.run</code>&nbsp;运行：</p>\n<pre class="lua"><code class="language-python">node3 = tf.add(node1, node2)\n<span class="code-built_in">print</span>(<span class="code-string"><span class="code-string">"node3: "</span></span>, node3)\n<span class="code-built_in">print</span>(<span class="code-string"><span class="code-string">"sess.run(node3): "</span></span>,sess.run(node3))</code></pre>\n<p>运行后会输出了以下内容：</p>\n<pre class="bash"><code class="language-python">node3:  Tensor(<span class="code-string"><span class="code-string">"Add_2:0"</span></span>, shape=(), dtype=<span\n        class="code-built_in">float</span>32)\nsess.run(node3):  <span class="hljs-number">7.0</span></code></pre>\n<p>到此，完成了TensorFlow创建图和执行图的过程。</p>\n<p>前面提到TensorFlow提供了一个名为TensorBoard的工具，这个工具能够显示图运算的节点。下面是一个TensorBoard可视化看到计算图的例子：</p>\n<p><img alt="TensorFlow 使用入门教程" height="130"\n        src="https://file.mahoooo.com/res/file/tensorflow_get_started_0.png" width="269"></p>\n<p>这样的常量运算结果并没有什么价值，因为他总是恒定的产生固定的结果。图中的节点能够以参数的方式接受外部输入——比如使用占位符。占位符可以等到模型运行时再使用动态计算的数值：</p>\n<pre class="ini"><code class="language-python"><span class="hljs-attr">a</span> = tf.placeholder(tf.float32)\n<span class="hljs-attr">b</span> = tf.placeholder(tf.float32)\n<span class="hljs-attr">adder_node</span> = a + b  <span\n            class="code-comment"># + 可以代替tf.add(a, b)构建模型</span></code></pre>\n<p>上面这3行代码有点像用一个function或者一个lambda表达式来获取参数输入。我们可以在运行时输入各种各样的参数到图中进行计算：</p>\n<pre class="css"><code class="language-python"><span class="code-selector-tag">print</span>(<span\n        class="code-selector-tag">sess</span><span class="code-selector-class">.run</span>(<span\n        class="code-selector-tag">adder_node</span>, {<span class="code-attribute">a</span>: <span\n        class="hljs-number"><span class="hljs-number">3</span></span>, b:<span class="hljs-number"><span\n        class="hljs-number">4.5</span></span>}))\n<span class="code-selector-tag">print</span>(<span class="code-selector-tag">sess</span><span\n            class="code-selector-class">.run</span>(<span class="code-selector-tag">adder_node</span>, {<span\n            class="code-attribute">a</span>: [<span class="hljs-number"><span class="hljs-number">1</span></span>,<span\n            class="hljs-number"><span class="hljs-number">3</span></span>], b: [<span class="hljs-number"><span\n            class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]}))</code></pre>\n<p>输出结果为：</p>\n<pre class="css"><code class="css">7<span class="code-selector-class"><span class="code-selector-class">.5</span></span>\n<span class="hljs-selector-attr"><span class="hljs-selector-attr">[ 3. &nbsp;7.]</span></span></code></pre>\n<p>在TensorBoard中，显示的计算图为：</p>\n<p><img alt="TensorFlow 使用入门教程" height="207"\n        src="https://file.mahoooo.com/res/file/tensorflow_get_started_1.png" width="243"></p>\n<p>我们可以使用更复杂的表达式来增加计算的内容：</p>\n<pre class="groovy"><code class="language-python">add_and_triple = adder_node * <span class="hljs-number"><span\n        class="hljs-number">3.</span></span>\nprint(sess.run(add_and_triple, {<span class="code-string">a:</span> <span class="hljs-number"><span class="hljs-number">3</span></span>, <span\n            class="code-string">b:</span><span class="hljs-number"><span class="hljs-number">4.5</span></span>}))</code></pre>\n<p>计算输出：</p>\n<pre class="css"><code class="css">22<span class="code-selector-class"><span\n        class="code-selector-class">.5</span></span></code></pre>\n<p>TensorBoard中的显示：</p>\n<p><img alt="TensorFlow 使用入门教程" height="337"\n        src="https://file.mahoooo.com/res/file/tensorflow_get_started_2.png" width="280"></p>\n<p>在机器学习中一个模型通常需要接收各种类型的数据作为输入。为了使得模型可以不断的训练通常需要能够针对相同的输入修改图的模型以获取新的输出。<strong>变量（Variables）</strong>可以增加可训练的参数到图中，他们由指定一个初始类型和初始值来创建：\n</p>\n<pre class="ini"><code class="language-python"><span class="hljs-attr">W</span> = tf.Variable([<span\n        class="hljs-number">.<span class="hljs-number">3</span></span>], tf.float32)\n<span class="hljs-attr">b</span> = tf.Variable([<span class="hljs-number">-.<span class="hljs-number">3</span></span>], tf.float32)\n<span class="hljs-attr">x</span> = tf.placeholder(tf.float32)\n<span class="hljs-attr">linear_model</span> = W * x + b</code></pre>\n<p>前面已经提到在调用&nbsp;<code>tf.constant</code>&nbsp;时会初始化不可变更的常量。 而这里通过调用&nbsp;<code>tf.Variable</code>&nbsp;创建的变量不会被初始化，为了在TensorFlow运行之前（<code>sess.run</code>执行模型运算之前）初始化所有的变量，需要增加一步&nbsp;<code>init</code>&nbsp;操作：\n</p>\n<pre class="swift"><code class="swift"><span class="code-keyword"><span class="code-keyword">init</span></span> = tf.global_variables_initializer()\nsess.run(<span class="code-keyword"><span class="code-keyword">init</span></span>)</code></pre>\n<p>可以通过重载&nbsp;<code>init</code>&nbsp;方式来全局初始化所有TensorFlow图中的变量。在上面的代码中，在我们调用&nbsp;<code>sess.run</code>&nbsp;之前，所有的变量都没有初始化。\n</p>\n<p>下面的&nbsp;<code>x</code>&nbsp;是一个占位符，<code>{x:[1,2,3,4]}</code>&nbsp;&nbsp;表示在运算中把x的值替换为[1,2,3,4]：</p>\n<pre class="css"><code class="language-python"><span class="code-selector-tag">print</span>(<span\n        class="code-selector-tag">sess</span><span class="code-selector-class">.run</span>(<span\n        class="code-selector-tag">linear_model</span>, {<span class="code-attribute">x</span>:[<span\n        class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span\n        class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span\n        class="hljs-number"><span class="hljs-number">4</span></span>]}))</code></pre>\n<p>输出：</p>\n<pre class="json"><code class="language-python">[ <span class="hljs-number"><span class="hljs-number">0.</span></span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span\n        class="hljs-number"><span class="hljs-number">0.30000001</span></span> &nbsp;<span class="hljs-number"><span\n        class="hljs-number">0.60000002</span></span> &nbsp;<span class="hljs-number"><span class="hljs-number">0.90000004</span></span>]</code></pre>\n<p>现在已经创建了一个计算模型，但是并不清晰是否足够有效，为了让他越来越有效，需要对这个模型进行数据训练。下面的代码定义名为&nbsp;<code>y</code>&nbsp;的占位符来提供所需的值，然后编写一个“损益功能”（loss\n    function）。</p>\n<p>一个“损益功能”是用来衡量当前的模型对于想达到的输出目标还有多少距离的工具。下面的例子使用线性回归作为损益模型。回归的过程是：计算模型的输出和损益变量（<code>y</code>）的差值，然后再对这个差值进行平方运算（方差），然后再把方差的结果向量进行和运算。下面的代码中，&nbsp;<code>linear_model\n    - y</code>&nbsp;创建了一个向量，向量中的每一个值表示对应的错误增量。然后调用&nbsp;<code>tf.square</code>&nbsp;对错误增量进行平方运算。最后将所有的方差结果相加创建一个数值的标量来抽象的表示错误差异，使用&nbsp;<code>tf.reduce_sum</code>来完成这一步工作。如下列代码：\n</p>\n<pre class="makefile"><code class="language-python"><span class="code-comment"><span class="code-comment"># 定义占位符</span></span>\ny = tf.placeholder(tf.float32)\n<span class="code-comment"><span class="code-comment"># 方差运算</span></span>\nsquared_deltas = tf.square(linear_model - y)\n<span class="code-comment"><span class="code-comment"># 定义损益模型</span></span>\nloss = tf.reduce_sum(squared_deltas)\n<span class="code-comment"><span class="code-comment"># 输出损益计算结果</span></span>\nprint(sess.run(loss, {x:[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span\n            class="hljs-number">3</span>,<span class="hljs-number">4</span>], y:[<span\n            class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">-2</span>,<span\n            class="hljs-number">-3</span>]}))</code></pre>\n<p>运算之后的差异值是：</p>\n<pre class="css"><code class="css">23<span class="code-selector-class"><span\n        class="code-selector-class">.66</span></span></code></pre>\n<p>\n    可以通过手动将&nbsp;<code>W</code>&nbsp;和&nbsp;<code>b</code>&nbsp;的值修改为-1和1降低差异结果。TensorFlow中使用&nbsp;<code>tf.Variable</code>&nbsp;创建变量，使用&nbsp;<code>tf.assign</code>&nbsp;修改变量。例如&nbsp;<code>W=-1</code>&nbsp;、<code>b=1</code>&nbsp;才是当前模型最佳的值，可以像下面这样修改他们的值：\n</p>\n<pre class="groovy"><code class="language-python">fixW = tf.assign(W, [<span class="hljs-number"><span\n        class="hljs-number">-1.</span></span>])\nfixb = tf.assign(b, [<span class="hljs-number"><span class="hljs-number">1.</span></span>])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {<span class="code-string">x:</span>[<span class="hljs-number"><span\n            class="hljs-number">1</span></span>,<span class="hljs-number"><span\n            class="hljs-number">2</span></span>,<span class="hljs-number"><span\n            class="hljs-number">3</span></span>,<span class="hljs-number"><span\n            class="hljs-number">4</span></span>], <span class="code-string">y:</span>[<span class="hljs-number"><span\n            class="hljs-number">0</span></span>,<span class="hljs-number"><span\n            class="hljs-number">-1</span></span>,<span class="hljs-number"><span\n            class="hljs-number">-2</span></span>,<span class="hljs-number"><span class="hljs-number">-3</span></span>]}))</code></pre>\n<p>修改之后的最终输出结果为：</p>\n<pre class="css"><code class="css">0<span class="code-selector-class"><span class="code-selector-class">.0</span></span></code></pre>\n\n<h3 id="h3-3">tf.train 接口</h3>\n<p>机器学习的完整过程超出了本文的范围，这里仅说明训练的过程。TensorFlow提供了很多优化器来逐渐（迭代或循环）调整每一个参数，最终实现损益值尽可能的小。最简单的优化器之一是“梯度递减”（<strong>gradient\n    descent</strong>），它会对损益计算模型求导，然后根据求导的结果调整输入变量的值（<code>W</code>和<code>b</code>），最终目的让求导的结果逐渐趋向于0。手工进行编写求导运算非常冗长且容易出错，TensorFlow还提供了函数&nbsp;<code>tf.gradients</code>&nbsp;实现自动求导过程。下面的例子展示了使用梯度递减训练样本的过程：\n</p>\n<pre class="bash"><code class="language-python"><span class="code-comment"><span class="code-comment"># 设定优化器，这里的0.01表示训练时的步进值</span></span>\noptimizer = tf.train.GradientDescentOptimizer(<span class="hljs-number">0.01</span>)\ntrain = optimizer.minimize(loss)\nsess.run(init) <span class="code-comment"><span class="code-comment"># 初始化变量值.</span></span>\n<span class="code-keyword"><span class="code-keyword">for</span></span> i <span class="code-keyword"><span\n            class="code-keyword">in</span></span> range(<span class="hljs-number">1000</span>): <span\n            class="code-comment"><span class="code-comment"># 遍历1000次训练数据，每次都重新设置新的W和b值</span></span>\n  sess.run(train, {x:[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span\n            class="hljs-number">3</span>,<span class="hljs-number">4</span>], y:[<span\n            class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">-2</span>,<span\n            class="hljs-number">-3</span>]})\n\n<span class="code-built_in">print</span>(sess.run([W, b]))</code></pre>\n<p>这个模式的运算结果是：</p>\n<pre class="json"><code class="json">[array([<span class="hljs-number"><span\n        class="hljs-number">-0.9999969</span></span>], dtype=float32), array([ <span class="hljs-number"><span\n        class="hljs-number">0.99999082</span></span>], dtype=float32)]</code></pre>\n<p>\n    现在我们已经完成机器学习的整个过程。虽然进行简单的线性回归计算并不需要用到太多的TensorFlow代码，但是这仅仅是一个用于实例的案例，在实际应用中往往需要编写更多的代码实现复杂的模型匹配运算。TensorFlow为常见的模式、结构和功能提供了更高级别的抽象接口。</p>\n\n<h3 id="h3-4">一个完整的训练过程</h3>\n<p>下面是根据前文的描述，编写的完整线性回归模型：</p>\n<pre class="makefile"><code class="language-python"><span class="code-keyword">import</span> numpy <span\n        class="code-keyword">as</span> np\n<span class="code-keyword">import</span> tensorflow <span class="code-keyword">as</span> tf\n\n<span class="code-comment"><span class="code-comment"># 模型参数</span></span>\nW = tf.Variable([<span class="hljs-number">.3</span>], tf.float32)\nb = tf.Variable([<span class="hljs-number">-.3</span>], tf.float32)\n<span class="code-comment"><span class="code-comment"># 模型输入</span></span>\nx = tf.placeholder(tf.float32)\n<span class="code-comment"><span class="code-comment"># 模型输出</span></span>\nlinear_model = W * x + b\n<span class="code-comment"><span class="code-comment"># 损益评估参数</span></span>\ny = tf.placeholder(tf.float32)\n<span class="code-comment"><span class="code-comment"># 损益模式</span></span>\nloss = tf.reduce_sum(tf.square(linear_model - y)) <span class="code-comment"># 方差和</span>\n<span class="code-comment"><span class="code-comment"># 优化器</span></span>\noptimizer = tf.train.GradientDescentOptimizer(<span class="hljs-number">0.01</span>)\ntrain = optimizer.minimize(loss)\n<span class="code-comment"><span class="code-comment"># 训练数据</span></span>\nx_train = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span\n            class="hljs-number">3</span>,<span class="hljs-number">4</span>]\ny_train = [<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span\n            class="hljs-number">-2</span>,<span class="hljs-number">-3</span>]\n<span class="code-comment"><span class="code-comment"># 定义训练的循环</span></span>\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init) <span class="code-comment"><span class="code-comment"># reset values to wrong</span></span>\n<span class="code-keyword">for</span> i <span class="code-keyword">in</span> range(<span class="hljs-number">1000</span>):\n  sess.run(train, {x:x_train, y:y_train})\n\n<span class="code-comment"><span class="code-comment"># 评估训练结果的精确性</span></span>\ncurr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\nprint(<span class="code-string">"W: %s b: %s loss: %s"</span>%(curr_W, curr_b, curr_loss))</code></pre>\n<p>运行后会输出：</p>\n<pre class="css"><code class="language-python"><span class="code-selector-tag">W</span>: <span\n        class="hljs-selector-attr">[</span><span class="hljs-number"><span class="hljs-selector-attr">-0.9999969</span></span><span\n        class="hljs-selector-attr">]</span> <span class="code-selector-tag">b</span>: <span\n        class="hljs-selector-attr">[ </span><span class="hljs-number"><span class="hljs-selector-attr">0.99999082</span></span><span\n        class="hljs-selector-attr">]</span> <span class="code-selector-tag">loss</span>: <span\n        class="hljs-number">5<span class="code-selector-class">.69997e-11</span></span></code></pre>\n<p>这个复杂的程序仍然可以在TensorBoard中可视化呈现：</p>\n<p><img alt="TensorFlow 使用入门教程" height="721"\n        src="https://file.mahoooo.com/res/file/tensorflow_get_started_3.png" width="832"></p>\n\n<h2 id="h2-4">tf.contrib.learn</h2>\n<p>前面已经提到，TensorFlow除了TensorFlow Core之外，为了便于业务开发还提供了很多更抽象的接口。<code>tf.contrib.learn</code>&nbsp;是TensorFlow的一个高级库，他提供了更加简化的机器学习机制，包括：\n</p>\n<ol>\n    <li>运行训练循环</li>\n    <li>运行评估循环</li>\n    <li>管理数据集合</li>\n    <li>管理训练数据</li>\n</ol>\n<p>tf.contrib.learn&nbsp;定义了一些通用模块。</p>\n\n<h4 id="h4-1">基本用法</h4>\n<p>先看看使用&nbsp;<code>tf.contrib.learn</code>&nbsp;来实现线性回归的方式。</p>\n<pre class="haskell"><code class="language-python"><span class="code-keyword"><span\n        class="code-keyword">import</span></span> tensorflow <span class="code-keyword"><span\n        class="code-keyword">as</span></span> tf\n<span class="code-comment"><span class="code-meta"># NumPy常用语加载、操作、预处理数据.</span></span>\n<span class="code-keyword"><span class="code-keyword">import</span></span> numpy <span class="code-keyword"><span\n            class="code-keyword">as</span></span> np\n\n<span class="code-comment"><span class="code-meta"># 定义一个特性列表features。</span></span>\n<span class="code-comment"><span class="code-meta"># 这里仅仅使用了real-valued特性。还有其他丰富的特性功能</span></span>\n<span class="code-title">features</span> = [tf.contrib.layers.real_valued_column(<span class="code-string"><span\n            class="code-string">"x"</span></span>, dimension=<span class="hljs-number"><span\n            class="hljs-number">1</span></span>)]\n\n<span class="code-comment"><span class="code-meta"># 一个评估者（estimator）是训练（fitting）与评估（inference）的开端。</span></span>\n<span class="code-comment"><span class="code-meta"># 这里预定于了许多类型的训练评估方式，比如线性回归（linear regression）、</span></span>\n<span class="code-comment"><span class="code-meta"># 逻辑回归（logistic regression）、线性分类（linear classification）和回归（regressors）</span></span>\n<span class="code-comment"><span class="code-meta"># 这里的estimator提供了线性回归的功能</span></span>\n<span class="code-title">estimator</span> = tf.contrib.learn.<span class="code-type">LinearRegressor</span>(feature_columns=features)\n\n<span class="code-comment"><span class="code-meta"># TensorFlow提供了许多帮助类来读取和设置数据集合</span></span>\n<span class="code-comment"><span class="code-meta"># 这里使用了‘numpy_input_fn’。</span></span>\n<span class="code-comment"><span class="code-meta"># 我们必须告诉方法我们许多多少批次的数据，以及每次批次的规模有多大。</span></span>\n<span class="code-title">x</span> = np.array([<span class="hljs-number"><span\n            class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">2.</span></span>, <span\n            class="hljs-number"><span class="hljs-number">3.</span></span>, <span class="hljs-number"><span\n            class="hljs-number">4.</span></span>])\n<span class="code-title">y</span> = np.array([<span class="hljs-number"><span\n            class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">-1.</span></span>, <span\n            class="hljs-number"><span class="hljs-number">-2.</span></span>, <span class="hljs-number"><span\n            class="hljs-number">-3.</span></span>])\n<span class="code-title">input_fn</span> = tf.contrib.learn.io.numpy_input_fn({<span class="code-string"><span\n            class="code-string">"x"</span></span>:x}, y, batch_size=<span class="hljs-number"><span class="hljs-number">4</span></span>,\n                                              num_epochs=<span class="hljs-number"><span class="hljs-number">1000</span></span>)\n\n<span class="code-comment"><span class="code-meta"># ‘fit’方法通过指定steps的值来告知方法要训练多少次数据</span></span>\n<span class="code-title">estimator</span>.fit(input_fn=input_fn, steps=<span class="hljs-number"><span\n            class="hljs-number">1000</span></span>)\n\n<span class="code-comment"><span class="code-meta"># 最后我们评估我们的模型价值。在一个实例中，我们希望使用单独的验证和测试数据集来避免过度拟合。</span></span>\n<span class="code-title">estimator</span>.evaluate(input_fn=input_fn)</code></pre>\n<p>运行后输出：</p>\n<pre class="lua"><code class="language-python">&nbsp; &nbsp; {<span class="code-string"><span class="code-string">\'global_step\'</span></span>: <span\n        class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="code-string"><span\n        class="code-string">\'loss\'</span></span>: <span class="hljs-number"><span\n        class="hljs-number">1.9650059e-11</span></span>}</code></pre>\n\n<h4 id="h4-2">自定义模型</h4>\n<p><code>tf.contrib.learn</code>&nbsp;并不限定只能使用它预设的模型。假设现在需要创建一个未预设到TensorFlow中的模型。我们依然可以使用<code>tf.contrib.learn</code>保留数据集合、训练数据、训练过程的高度抽象。我们将使用我们对较低级别TensorFlow\n    API的了解，展示如何使用LinearRegressor实现自己的等效模型。</p>\n<p>使用&nbsp;<code>tf.contrib.learn</code>&nbsp;创建一个自定义模型需要用到它的子类&nbsp;<code>tf.contrib.learn.Estimator</code>&nbsp;。而&nbsp;<code>tf.contrib.learn.LinearRegressor</code>&nbsp;是&nbsp;&nbsp;<code>tf.contrib.learn.Estimator</code>&nbsp;的子类。下面的代码中为&nbsp;<code>Estimator</code>&nbsp;新增了一个&nbsp;<code>model_fn</code>&nbsp;功能，这个功能将告诉&nbsp;<code>tf.contrib.learn</code>&nbsp;如何进行评估、训练以及损益计算：\n</p>\n<pre class="python"><code class="language-python"><span class="code-keyword"><span\n        class="code-keyword">import</span></span> numpy <span class="code-keyword"><span class="code-keyword">as</span></span> np\n<span class="code-keyword"><span class="code-keyword">import</span></span> tensorflow <span class="code-keyword"><span\n            class="code-keyword">as</span></span> tf\n<span class="code-comment"><span class="code-comment"># 定义一个特征数组，这里仅提供实数特征</span></span>\n<span class="hljs-function"><span class="code-keyword"><span class="hljs-function"><span class="code-keyword">def</span></span></span><span\n        class="hljs-function"> </span><span class="code-title"><span class="hljs-function"><span class="code-title">model</span></span></span><span\n        class="hljs-params"><span class="hljs-function"><span class="hljs-params">(features, labels, mode)</span></span></span><span\n        class="hljs-function">:</span></span>\n  <span class="code-comment"><span class="code-comment"># 构建线性模型和预设值</span></span>\n  W = tf.get_variable(<span class="code-string"><span class="code-string">"W"</span></span>, [<span class="hljs-number"><span\n            class="hljs-number">1</span></span>], dtype=tf.float64)\n  b = tf.get_variable(<span class="code-string"><span class="code-string">"b"</span></span>, [<span class="hljs-number"><span\n            class="hljs-number">1</span></span>], dtype=tf.float64)\n  y = W*features[<span class="code-string"><span class="code-string">\'x\'</span></span>] + b\n  <span class="code-comment"><span class="code-comment"># 损益子图</span></span>\n  loss = tf.reduce_sum(tf.square(y - labels))\n  <span class="code-comment"><span class="code-comment"># 训练子图</span></span>\n  global_step = tf.train.get_global_step()\n  optimizer = tf.train.GradientDescentOptimizer(<span class="hljs-number"><span class="hljs-number">0.01</span></span>)\n  train = tf.group(optimizer.minimize(loss),\n                   tf.assign_add(global_step, <span class="hljs-number"><span class="hljs-number">1</span></span>))\n  <span class="code-comment"><span class="code-comment"># ModelFnOps方法将创建我们自定义的一个抽象模型。</span></span>\n  <span class="code-keyword"><span class="code-keyword">return</span></span> tf.contrib.learn.ModelFnOps(\n      mode=mode, predictions=y,\n      loss=loss,\n      train_op=train)\n\nestimator = tf.contrib.learn.Estimator(model_fn=model)\n<span class="code-comment"><span class="code-comment"># 定义数据集</span></span>\nx = np.array([<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span\n            class="hljs-number">2.</span></span>, <span class="hljs-number"><span class="hljs-number">3.</span></span>, <span\n            class="hljs-number"><span class="hljs-number">4.</span></span>])\ny = np.array([<span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span\n            class="hljs-number">-1.</span></span>, <span class="hljs-number"><span class="hljs-number">-2.</span></span>, <span\n            class="hljs-number"><span class="hljs-number">-3.</span></span>])\ninput_fn = tf.contrib.learn.io.numpy_input_fn({<span class="code-string"><span class="code-string">"x"</span></span>: x}, y, <span\n            class="hljs-number"><span class="hljs-number">4</span></span>, num_epochs=<span class="hljs-number"><span\n            class="hljs-number">1000</span></span>)\n\n<span class="code-comment"><span class="code-comment"># 训练数据</span></span>\nestimator.fit(input_fn=input_fn, steps=<span class="hljs-number"><span class="hljs-number">1000</span></span>)\n<span class="code-comment"><span class="code-comment"># 评估模型</span></span>\nprint(estimator.evaluate(input_fn=input_fn, steps=<span class="hljs-number"><span class="hljs-number">10</span></span>))</code></pre>\n<p>运行后输出：</p>\n<pre class="lua"><code class="language-python">{<span class="code-string"><span class="code-string">\'loss\'</span></span>: <span\n        class="hljs-number"><span class="hljs-number">5.9819476e-11</span></span>, <span class="code-string"><span\n        class="code-string">\'global_step\'</span></span>: <span class="hljs-number"><span class="hljs-number">1000</span></span>}</code></pre>\n\n<h2 id="h2-5">接下来做什么</h2>\n<p>阅读了到这里，你应该初步了解如何在TensorFlow中进行开发和编码。但是如果你刚踏入机器学习的领域，就算很仔细的看了本文，对于如何使用TensorFlow进行机器学习基本上还是懵逼的。<span\n        style="color:#FF0000">请继续阅读</span><a href="https://my.oschina.net/chkui/blog/888346" rel="nofollow">《MNIST\n    机器学习入门</a>》<span style="color:#FF0000">，文章给出了一个完整的机器学习建模案例，适合零知识入门机器学习。</span></p>'}});